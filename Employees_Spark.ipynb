{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "aff0a6b4ec3a9cf15ae5d70a5c7ecac07e8a7f43b412a755232c9c99d1062fc8"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Project: Data Analysis on employees\n\n- Task 1: Generate DataFrame from CSV data.\n- Task 2: Define a schema for the data.\n- Task 3: Display schema of DataFrame.\n- Task 4: Create a temporary view.\n- Task 5: Execute an SQL query.\n- Task 6: Calculate Average Salary by Department.\n- Task 7: Filter and Display IT Department Employees.\n- Task 8: Add 10% Bonus to Salaries.\n- Task 9: Find Maximum Salary by Age.\n- Task 10: Self-Join on Employee Data.\n- Task 11: Calculate Average Employee Age.\n- Task 12: Calculate Total Salary by Department.\n- Task 13: Sort Data by Age and Salary.\n- Task 14: Count Employees in Each Department.\n- Task 15: Filter Employees with the letter o in the Name.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Installing required packages \n!pip install pyspark  findspark wget",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Requirement already satisfied: pyspark in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (3.1.2)\n,Requirement already satisfied: findspark in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.0.1)\n,Requirement already satisfied: wget in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (3.2)\n,Requirement already satisfied: py4j==0.10.9 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pyspark) (0.10.9)\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import findspark\n\nfindspark.init()",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# Creating a SparkContext object  \n\nsc = SparkContext.getOrCreate()\n\n# Creating a SparkSession  \n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark DataFrames basic example\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "25/08/18 23:34:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n,Setting default log level to \"WARN\".\n,To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "# Download the CSV data first into a local `employees.csv` file\nimport wget\nwget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/data/employees.csv\")",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'employees (1).csv'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "### Tasks\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 1: Generate a Spark DataFrame from the CSV data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Read data from the \"emp\" CSV file and import it into a DataFrame variable named \"employees_df\"  \nemployees_df1 = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 2: Define a schema for the data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Schema for the input data and read the file using the user-defined Schema\nschema = StructType([\n    StructField(\"Emp_No\", IntegerType(), True),\n    StructField(\"Emp_name\", StringType(), True),\n    StructField(\"Salary\", IntegerType(), True),\n    StructField(\"Age\", IntegerType(), True),\n    StructField(\"Department\", StringType(), True)\n])\nemployees_df2 = spark.read.csv(\"employees.csv\", schema=schema, header=True)\n\n",
      "metadata": {},
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 3: Display schema of DataFrame",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Display all columns of the DataFrame, along with their respective data types\nemployees_df2.printSchema()",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "root\n, |-- Emp_No: integer (nullable = true)\n, |-- Emp_name: string (nullable = true)\n, |-- Salary: integer (nullable = true)\n, |-- Age: integer (nullable = true)\n, |-- Department: string (nullable = true)\n,\n"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 4: Create a temporary view",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a temporary view named \"employees\" for the DataFrame\nspark.sql(\"DROP VIEW IF EXISTS employees\")\n\nemployees_df2.createTempView('employees')",
      "metadata": {},
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 5: Execute an SQL query",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# SQL query to fetch solely the records from the View where the age exceeds 30\nspark.sql('SELECT * FROM employees WHERE Age > 30').show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------+-----------+------+---+----------+\n,|Emp_No|   Emp_name|Salary|Age|Department|\n,+------+-----------+------+---+----------+\n,|   199|    Douglas|  2600| 34|     Sales|\n,|   200|   Jennifer|  4400| 36| Marketing|\n,|   201|    Michael| 13000| 32|        IT|\n,|   202|        Pat|  6000| 39|        HR|\n,|   203|      Susan|  6500| 36| Marketing|\n,|   205|    Shelley| 12008| 33|   Finance|\n,|   206|    William|  8300| 37|        IT|\n,|   100|     Steven| 24000| 39|        IT|\n,|   102|        Lex| 17000| 37| Marketing|\n,|   103|  Alexander|  9000| 39| Marketing|\n,|   104|      Bruce|  6000| 38|        IT|\n,|   105|      David|  4800| 39|        IT|\n,|   106|      Valli|  4800| 38|     Sales|\n,|   107|      Diana|  4200| 35|     Sales|\n,|   109|     Daniel|  9000| 35|        HR|\n,|   110|       John|  8200| 31| Marketing|\n,|   111|     Ismael|  7700| 32|        IT|\n,|   112|Jose Manuel|  7800| 34|        HR|\n,|   113|       Luis|  6900| 34|     Sales|\n,|   116|     Shelli|  2900| 37|   Finance|\n,+------+-----------+------+---+----------+\n,only showing top 20 rows\n,\n"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 6: Calculate Average Salary by Department",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# SQL query to calculate the average salary of employees grouped by department\nspark.sql('SELECT Department, ROUND(AVG(Salary),2) AS avg_Salary FROM employees GROUP BY Department').show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+----------+----------+\n,|Department|avg_Salary|\n,+----------+----------+\n,|     Sales|   5492.92|\n,|        HR|    5837.5|\n,|   Finance|    5730.8|\n,| Marketing|   6633.33|\n,|        IT|    7400.0|\n,+----------+----------+\n,\n"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 7: Filter and Display IT Department Employees",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Apply a filter to select records where the department is 'IT'\nemployees_df2.filter(\"Department = 'IT'\").show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------+--------+------+---+----------+\n,|Emp_No|Emp_name|Salary|Age|Department|\n,+------+--------+------+---+----------+\n,|   198|  Donald|  2600| 29|        IT|\n,|   201| Michael| 13000| 32|        IT|\n,|   206| William|  8300| 37|        IT|\n,|   100|  Steven| 24000| 39|        IT|\n,|   104|   Bruce|  6000| 38|        IT|\n,|   105|   David|  4800| 39|        IT|\n,|   111|  Ismael|  7700| 32|        IT|\n,|   129|   Laura|  3300| 38|        IT|\n,|   132|      TJ|  2100| 34|        IT|\n,|   136|   Hazel|  2200| 29|        IT|\n,+------+--------+------+---+----------+\n,\n"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 8: Add 10% Bonus to Salaries",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql.functions import col\n\n# Add a new column \"SalaryAfterBonus\" with 10% bonus added to the original salary\nemployees_df2 = employees_df2.withColumn(\"SalaryAfterBonus\", col(\"Salary\") * 1.1)\nemployees_df2.show(5)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------+--------+------+---+----------+------------------+\n,|Emp_No|Emp_name|Salary|Age|Department|  SalaryAfterBonus|\n,+------+--------+------+---+----------+------------------+\n,|   198|  Donald|  2600| 29|        IT|2860.0000000000005|\n,|   199| Douglas|  2600| 34|     Sales|2860.0000000000005|\n,|   200|Jennifer|  4400| 36| Marketing|            4840.0|\n,|   201| Michael| 13000| 32|        IT|14300.000000000002|\n,|   202|     Pat|  6000| 39|        HR| 6600.000000000001|\n,+------+--------+------+---+----------+------------------+\n,only showing top 5 rows\n,\n"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 9: Find Maximum Salary by Age",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql.functions import max\n\n# Group data by age and calculate the maximum salary for each age group\nemployees_df2.groupby(\"Age\").agg(max(\"Salary\").alias(\"Max_Salary\")).show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+---+----------+\n,|Age|Max_Salary|\n,+---+----------+\n,| 31|      8200|\n,| 34|      7800|\n,| 28|     12008|\n,| 27|     17000|\n,| 26|      3600|\n,| 37|     17000|\n,| 35|      9000|\n,| 39|     24000|\n,| 38|      6000|\n,| 29|     10000|\n,| 32|     13000|\n,| 33|     12008|\n,| 30|      8000|\n,| 36|      7900|\n,+---+----------+\n,\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 10: Self-Join on Employee Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Join the DataFrame with itself based on the \"Emp_No\" column\nemployees_df2_joined = employees_df2.join(employees_df2, \"Emp_No\")\nemployees_df2_joined.show()\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n,|Emp_No| Emp_name|Salary|Age|Department|  SalaryAfterBonus| Emp_name|Salary|Age|Department|  SalaryAfterBonus|\n,+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n,|   198|   Donald|  2600| 29|        IT|2860.0000000000005|   Donald|  2600| 29|        IT|2860.0000000000005|\n,|   199|  Douglas|  2600| 34|     Sales|2860.0000000000005|  Douglas|  2600| 34|     Sales|2860.0000000000005|\n,|   200| Jennifer|  4400| 36| Marketing|            4840.0| Jennifer|  4400| 36| Marketing|            4840.0|\n,|   201|  Michael| 13000| 32|        IT|14300.000000000002|  Michael| 13000| 32|        IT|14300.000000000002|\n,|   202|      Pat|  6000| 39|        HR| 6600.000000000001|      Pat|  6000| 39|        HR| 6600.000000000001|\n,|   203|    Susan|  6500| 36| Marketing| 7150.000000000001|    Susan|  6500| 36| Marketing| 7150.000000000001|\n,|   204|  Hermann| 10000| 29|   Finance|           11000.0|  Hermann| 10000| 29|   Finance|           11000.0|\n,|   205|  Shelley| 12008| 33|   Finance|13208.800000000001|  Shelley| 12008| 33|   Finance|13208.800000000001|\n,|   206|  William|  8300| 37|        IT|            9130.0|  William|  8300| 37|        IT|            9130.0|\n,|   100|   Steven| 24000| 39|        IT|26400.000000000004|   Steven| 24000| 39|        IT|26400.000000000004|\n,|   101|    Neena| 17000| 27|     Sales|           18700.0|    Neena| 17000| 27|     Sales|           18700.0|\n,|   102|      Lex| 17000| 37| Marketing|           18700.0|      Lex| 17000| 37| Marketing|           18700.0|\n,|   103|Alexander|  9000| 39| Marketing|            9900.0|Alexander|  9000| 39| Marketing|            9900.0|\n,|   104|    Bruce|  6000| 38|        IT| 6600.000000000001|    Bruce|  6000| 38|        IT| 6600.000000000001|\n,|   105|    David|  4800| 39|        IT|            5280.0|    David|  4800| 39|        IT|            5280.0|\n,|   106|    Valli|  4800| 38|     Sales|            5280.0|    Valli|  4800| 38|     Sales|            5280.0|\n,|   107|    Diana|  4200| 35|     Sales|            4620.0|    Diana|  4200| 35|     Sales|            4620.0|\n,|   108|    Nancy| 12008| 28|     Sales|13208.800000000001|    Nancy| 12008| 28|     Sales|13208.800000000001|\n,|   109|   Daniel|  9000| 35|        HR|            9900.0|   Daniel|  9000| 35|        HR|            9900.0|\n,|   110|     John|  8200| 31| Marketing|            9020.0|     John|  8200| 31| Marketing|            9020.0|\n,+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n,only showing top 20 rows\n,\n"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 11: Calculate Average Employee Age",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Calculate the average age of employees\nfrom pyspark.sql.functions import avg \nemployees_df2.agg(avg(\"Age\")).show()\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+--------+\n,|avg(Age)|\n,+--------+\n,|   33.56|\n,+--------+\n,\n"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 12: Calculate Total Salary by Department",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Calculate the total salary for each department. Hint - User GroupBy and Aggregate functions\nfrom pyspark.sql.functions import sum \nemployees_df2.groupby(\"Department\").agg(sum(\"Salary\").alias(\"Total_Salary\")).show()\nemployees_df2.groupby(\"Department\").agg({\"Salary\": \"SUM\"}).show()",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+----------+------------+\n,|Department|Total_Salary|\n,+----------+------------+\n,|     Sales|       71408|\n,|        HR|       46700|\n,|   Finance|       57308|\n,| Marketing|       59700|\n,|        IT|       74000|\n,+----------+------------+\n,\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+----------+-----------+\n,|Department|sum(Salary)|\n,+----------+-----------+\n,|     Sales|      71408|\n,|        HR|      46700|\n,|   Finance|      57308|\n,| Marketing|      59700|\n,|        IT|      74000|\n,+----------+-----------+\n,\n"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 13: Sort Data by Age and Salary",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Sort the DataFrame by age in ascending order and then by salary in descending order\nemployees_df2.orderBy(col(\"Age\").asc(), col(\"Salary\").desc()).show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------+---------+------+---+----------+------------------+\n,|Emp_No| Emp_name|Salary|Age|Department|  SalaryAfterBonus|\n,+------+---------+------+---+----------+------------------+\n,|   137|   Renske|  3600| 26| Marketing|3960.0000000000005|\n,|   101|    Neena| 17000| 27|     Sales|           18700.0|\n,|   114|      Den| 11000| 27|   Finance|12100.000000000002|\n,|   108|    Nancy| 12008| 28|     Sales|13208.800000000001|\n,|   130|    Mozhe|  2800| 28| Marketing|3080.0000000000005|\n,|   126|    Irene|  2700| 28|        HR|2970.0000000000005|\n,|   204|  Hermann| 10000| 29|   Finance|           11000.0|\n,|   115|Alexander|  3100| 29|   Finance|3410.0000000000005|\n,|   134|  Michael|  2900| 29|     Sales|3190.0000000000005|\n,|   198|   Donald|  2600| 29|        IT|2860.0000000000005|\n,|   140|   Joshua|  2500| 29|   Finance|            2750.0|\n,|   136|    Hazel|  2200| 29|        IT|            2420.0|\n,|   120|  Matthew|  8000| 30|        HR|            8800.0|\n,|   110|     John|  8200| 31| Marketing|            9020.0|\n,|   127|    James|  2400| 31|        HR|            2640.0|\n,|   201|  Michael| 13000| 32|        IT|14300.000000000002|\n,|   111|   Ismael|  7700| 32|        IT|            8470.0|\n,|   119|    Karen|  2500| 32|   Finance|            2750.0|\n,|   205|  Shelley| 12008| 33|   Finance|13208.800000000001|\n,|   124|    Kevin|  5800| 33| Marketing| 6380.000000000001|\n,+------+---------+------+---+----------+------------------+\n,only showing top 20 rows\n,\n"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 14: Count Employees in Each Department",
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql.functions import count\n\n# Calculate the number of employees in each department\nemployees_df2.groupBy(\"Department\").agg({\"Emp_No\": \"COUNT\"}).show()\nemployees_df2.groupBy(\"Department\").agg(count(\"Emp_No\")).show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+----------+-------------+\n,|Department|count(Emp_No)|\n,+----------+-------------+\n,|     Sales|           13|\n,|        HR|            8|\n,|   Finance|           10|\n,| Marketing|            9|\n,|        IT|           10|\n,+----------+-------------+\n,\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+----------+-------------+\n,|Department|count(Emp_No)|\n,+----------+-------------+\n,|     Sales|           13|\n,|        HR|            8|\n,|   Finance|           10|\n,| Marketing|            9|\n,|        IT|           10|\n,+----------+-------------+\n,\n"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "#### Task 15: Filter Employees with the letter o in the Name",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Apply a filter to select records where the employee's name contains the letter 'o'\nspark.sql(\"SELECT * FROM employees WHERE Emp_Name LIKE '%o%'\").show()",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------+-----------+------+---+----------+\n,|Emp_No|   Emp_name|Salary|Age|Department|\n,+------+-----------+------+---+----------+\n,|   198|     Donald|  2600| 29|        IT|\n,|   199|    Douglas|  2600| 34|     Sales|\n,|   110|       John|  8200| 31| Marketing|\n,|   112|Jose Manuel|  7800| 34|        HR|\n,|   130|      Mozhe|  2800| 28| Marketing|\n,|   133|      Jason|  3300| 38|     Sales|\n,|   139|       John|  2700| 36|     Sales|\n,|   140|     Joshua|  2500| 29|   Finance|\n,+------+-----------+------+---+----------+\n,\n"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log -->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-09-01|0.1|Lavanya T S|Initial version|\n|2023-09-11|0.2|Pornima More|QA pass with edits|-->\n",
      "metadata": {}
    }
  ]
}